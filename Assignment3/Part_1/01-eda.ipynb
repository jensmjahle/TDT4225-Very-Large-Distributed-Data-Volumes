{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T11:08:30.572122Z",
     "start_time": "2025-10-31T11:08:30.557122Z"
    }
   },
   "source": "import pandas as pd\nimport numpy as np\nimport json\nimport ast\nimport csv\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "19055f1e-bb15-4034-9a96-e98cd97de6e2",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T11:08:30.604118Z",
     "start_time": "2025-10-31T11:08:30.588123Z"
    }
   },
   "source": "#Helper functions\ndef parse_json_safe(x):\n    if pd.isna(x) or x == '':\n        return []\n    try:\n        return json.loads(x) if isinstance(x, str) else x\n    except Exception:\n        try:\n            return ast.literal_eval(x)\n        except Exception:\n            return []\n\ndef pretty_print(df, title=None, n=5):\n    if title:\n        print(f\"\\n===== {title} =====\")\n    print(tabulate(df.head(n), headers=\"keys\", tablefmt=\"fancy_grid\"))\n    if len(df) > n:\n        print(f\"... ({len(df) - n} more rows)\")\n",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7e3391642733f366",
   "metadata": {
    "collapsed": false,
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T11:12:46.659260Z",
     "start_time": "2025-10-31T11:08:30.613121Z"
    }
   },
   "source": [
    "bad_movie_lines = []\n",
    "bad_credit_lines = []\n",
    "bad_keyword_lines = []\n",
    "bad_links_lines = []\n",
    "bad_ratings_lines = []\n",
    "\n",
    "def log_bad_movie(line):\n",
    "    bad_movie_lines.append(line)\n",
    "    return None\n",
    "\n",
    "def log_bad_credit(line):\n",
    "    bad_credit_lines.append(line)\n",
    "    return None\n",
    "\n",
    "def log_bad_keyword(line):\n",
    "    bad_keyword_lines.append(line)\n",
    "    return None\n",
    "\n",
    "def log_bad_links(line):\n",
    "    bad_links_lines.append(line)\n",
    "    return None\n",
    "\n",
    "def log_bad_ratings(line):\n",
    "    bad_ratings_lines.append(line)\n",
    "\n",
    "movies = pd.read_csv(\n",
    "    \"../movies/movies_metadata.csv\",\n",
    "    engine=\"python\",\n",
    "    sep=\",\",\n",
    "    quotechar='\"',\n",
    "    on_bad_lines=lambda line: log_bad_movie(line)\n",
    ")\n",
    "\n",
    "movie_credits = pd.read_csv(\n",
    "    \"../movies/credits.csv\",\n",
    "    engine=\"python\",\n",
    "    sep=\",\",\n",
    "    quotechar='\"',\n",
    "    on_bad_lines=lambda line: log_bad_credit(line)\n",
    ")\n",
    "\n",
    "keywords = pd.read_csv(\n",
    "    \"../movies/keywords.csv\",\n",
    "    engine=\"python\",\n",
    "    sep=\",\",\n",
    "    quotechar='\"',\n",
    "    on_bad_lines=lambda line: log_bad_keyword(line)\n",
    ")\n",
    "\n",
    "links = pd.read_csv(\n",
    "    \"../movies/links.csv\",\n",
    "    engine=\"python\",\n",
    "    sep=\",\",\n",
    "    quotechar='\"',\n",
    "    on_bad_lines=lambda line: log_bad_movie(line)\n",
    ")\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    \"../movies/ratings.csv\",\n",
    "    engine=\"python\",\n",
    "    sep=\",\",\n",
    "    quotechar='\"',\n",
    "    on_bad_lines=lambda line: log_bad_movie(line)\n",
    ")\n",
    "\n",
    "print(\"Datasets loaded.\")\n",
    "print(f\"movies: {movies.shape}\")\n",
    "print(f\"credits: {movie_credits.shape}\")\n",
    "print(f\"keywords: {keywords.shape}\")\n",
    "print(f\"links: {links.shape}\")\n",
    "print(f\"ratings: {ratings.shape}\")\n",
    "\n",
    "print(f\"movies skipped lines: {len(bad_movie_lines)}\")\n",
    "print(f\"credits skipped lines: {len(bad_credit_lines)}\")\n",
    "print(f\"keywords skipped lines: {len(bad_keyword_lines)}\")\n",
    "print(f\"links skipped lines: {len(bad_links_lines)}\")\n",
    "print(f\"ratings skipped lines: {len(bad_ratings_lines)}\")\n",
    "\n",
    "if bad_movie_lines:\n",
    "    print(\"example bad movie line:\")\n",
    "    print(bad_movie_lines[0][:200])\n",
    "else:\n",
    "    print(\"No bad movie lines found.\")\n",
    "if bad_credit_lines:\n",
    "    print(\"example bad credit line:\")\n",
    "    print(bad_credit_lines[0][:200])\n",
    "else:\n",
    "    print(\"No bad credit lines found.\")\n",
    "if bad_keyword_lines:\n",
    "    print(\"example bad keyword line:\")\n",
    "    print(bad_keyword_lines[0][:200])\n",
    "else:\n",
    "    print(\"No bad keyword lines found.\")\n",
    "if bad_links_lines:\n",
    "    print(\"example bad links:\")\n",
    "    print(bad_links_lines[0][:200])\n",
    "else:\n",
    "    print(\"No bad links lines found.\")\n",
    "if bad_ratings_lines:\n",
    "    print(\"example bad ratings:\")\n",
    "    print(bad_ratings_lines[0][:200])\n",
    "else:\n",
    "    print(\"No bad ratings lines found.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded.\n",
      "movies: (45466, 24)\n",
      "credits: (45476, 3)\n",
      "keywords: (46419, 2)\n",
      "links: (45843, 3)\n",
      "ratings: (26024289, 4)\n",
      "movies skipped lines: 0\n",
      "credits skipped lines: 0\n",
      "keywords skipped lines: 0\n",
      "links skipped lines: 0\n",
      "ratings skipped lines: 0\n",
      "No bad movie lines found.\n",
      "No bad credit lines found.\n",
      "No bad keyword lines found.\n",
      "No bad links lines found.\n",
      "No bad ratings lines found.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:13:03.607660Z",
     "start_time": "2025-10-31T11:12:48.033808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def data_overview(df, name):\n",
    "    print(f\"\\n===== Overview of {name} =====\")\n",
    "    summary = pd.DataFrame({\n",
    "        \"dtype\": df.dtypes,\n",
    "        \"unique_values\": df.nunique(),\n",
    "        \"missing_count\": df.isnull().sum(),\n",
    "        \"missing_percent\": (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    summary = summary.sort_values(\"missing_count\", ascending=False)\n",
    "    print(summary)\n",
    "\n",
    "    for col in df.columns:\n",
    "        unique_count = df[col].nunique(dropna=True)\n",
    "        if unique_count < 10:\n",
    "            print(\"\\n--- Columns with < 10 Unique Values ---\")\n",
    "            unique_vals = df[col].dropna().unique()\n",
    "            print(f\"\\n{col} ({unique_count} unique values):\")\n",
    "            print(unique_vals)\n",
    "\n",
    "\n",
    "data_overview(movies, \"Movies Metadata\")\n",
    "data_overview(movie_credits, \"Credits\")\n",
    "data_overview(keywords, \"Keywords\")\n",
    "data_overview(links, \"Links Small\")\n",
    "data_overview(ratings, \"Ratings Small\")"
   ],
   "id": "b99f717902384f21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Overview of Movies Metadata =====\n",
      "                         dtype  unique_values  missing_count  missing_percent\n",
      "belongs_to_collection   object           1698          40972            90.12\n",
      "homepage                object           7673          37684            82.88\n",
      "tagline                 object          20283          25054            55.10\n",
      "overview                object          44307            954             2.10\n",
      "poster_path             object          45024            386             0.85\n",
      "runtime                float64            353            263             0.58\n",
      "status                  object              6             87             0.19\n",
      "release_date            object          17336             87             0.19\n",
      "imdb_id                 object          45417             17             0.04\n",
      "original_language       object             92             11             0.02\n",
      "vote_average           float64             92              6             0.01\n",
      "vote_count             float64           1820              6             0.01\n",
      "title                   object          42277              6             0.01\n",
      "video                   object              2              6             0.01\n",
      "spoken_languages        object           1931              6             0.01\n",
      "revenue                float64           6863              6             0.01\n",
      "popularity              object          43758              5             0.01\n",
      "production_countries    object           2393              3             0.01\n",
      "production_companies    object          22708              3             0.01\n",
      "genres                  object           4069              0             0.00\n",
      "id                      object          45436              0             0.00\n",
      "adult                   object              5              0             0.00\n",
      "budget                  object           1226              0             0.00\n",
      "original_title          object          43373              0             0.00\n",
      "\n",
      "--- Columns with < 10 Unique Values ---\n",
      "\n",
      "adult (5 unique values):\n",
      "['False' 'True' ' - Written by Ørnås'\n",
      " ' Rune Balot goes to a casino connected to the October corporation to try to wrap up her case once and for all.'\n",
      " ' Avalanche Sharks tells the story of a bikini contest that turns into a horrifying affair when it is hit by a shark avalanche.']\n",
      "\n",
      "--- Columns with < 10 Unique Values ---\n",
      "\n",
      "status (6 unique values):\n",
      "['Released' 'Rumored' 'Post Production' 'In Production' 'Planned'\n",
      " 'Canceled']\n",
      "\n",
      "--- Columns with < 10 Unique Values ---\n",
      "\n",
      "video (2 unique values):\n",
      "[False True]\n",
      "\n",
      "===== Overview of Credits =====\n",
      "       dtype  unique_values  missing_count  missing_percent\n",
      "cast  object          43019              0              0.0\n",
      "crew  object          44669              0              0.0\n",
      "id     int64          45432              0              0.0\n",
      "\n",
      "===== Overview of Keywords =====\n",
      "           dtype  unique_values  missing_count  missing_percent\n",
      "id         int64          45432              0              0.0\n",
      "keywords  object          25989              0              0.0\n",
      "\n",
      "===== Overview of Links Small =====\n",
      "           dtype  unique_values  missing_count  missing_percent\n",
      "tmdbId   float64          45594            219             0.48\n",
      "movieId    int64          45843              0             0.00\n",
      "imdbId     int64          45843              0             0.00\n",
      "\n",
      "===== Overview of Ratings Small =====\n",
      "             dtype  unique_values  missing_count  missing_percent\n",
      "userId       int64         270896              0              0.0\n",
      "movieId      int64          45115              0              0.0\n",
      "rating     float64             10              0              0.0\n",
      "timestamp    int64       20549435              0              0.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:13:30.236027Z",
     "start_time": "2025-10-31T11:13:03.629820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_duplicates(df, keys, name=None, show_examples=True):\n",
    "    if name:\n",
    "        print(f\"\\n--- Checking Duplicates in {name} ---\")\n",
    "\n",
    "    missing_keys = [k for k in keys if k not in df.columns]\n",
    "    if missing_keys:\n",
    "        print(f\"Missing key columns: {missing_keys}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    duplicate_mask = df.duplicated(subset=keys, keep=False)\n",
    "    key_dupes_df = df.loc[duplicate_mask].sort_values(by=keys)\n",
    "\n",
    "    duplicate_key_groups = (\n",
    "        key_dupes_df[keys]\n",
    "        .drop_duplicates()\n",
    "        .shape[0]\n",
    "        if not key_dupes_df.empty\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    full_duplicates = df.duplicated(keep=False)\n",
    "    full_dupes_df = df.loc[full_duplicates]\n",
    "    full_dupes_count = full_dupes_df.drop_duplicates().shape[0] if not full_dupes_df.empty else 0\n",
    "\n",
    "    partial_dupes_df = key_dupes_df.merge(\n",
    "        full_dupes_df.drop_duplicates(),\n",
    "        how=\"left\",\n",
    "        indicator=True\n",
    "    ).query('_merge == \"left_only\"').drop(columns=\"_merge\")\n",
    "\n",
    "    if not partial_dupes_df.empty:\n",
    "        diff_info = []\n",
    "        for key_values, group in partial_dupes_df.groupby(keys):\n",
    "            # find columns with more than one unique non-null value in this group\n",
    "            differing_cols = [\n",
    "                col for col in group.columns\n",
    "                if col not in keys and group[col].nunique(dropna=False) > 1\n",
    "            ]\n",
    "            group = group.copy()\n",
    "            group[\"diff_columns\"] = \", \".join(differing_cols) if differing_cols else np.nan\n",
    "            diff_info.append(group)\n",
    "        partial_dupes_df = pd.concat(diff_info, ignore_index=True)\n",
    "\n",
    "    print(f\"Duplicate groups based on keys {keys}: {duplicate_key_groups}\")\n",
    "    print(f\"Fully duplicate rows (identical across all columns): {full_dupes_count}\")\n",
    "\n",
    "    if not partial_dupes_df.empty and show_examples:\n",
    "        print(\"\\nExample duplicate rows based on keys:\")\n",
    "        print(partial_dupes_df.head(10))\n",
    "\n",
    "    return key_dupes_df\n",
    "\n",
    "\n",
    "find_duplicates(movies, ['id'], \"Movies Metadata\")\n",
    "find_duplicates(movie_credits, ['id'], \"Credits\")\n",
    "find_duplicates(keywords, ['id'], \"Keywords\")\n",
    "find_duplicates(links, ['movieId'], \"Links\")\n",
    "find_duplicates(ratings, ['movieId', 'userId'], \"Ratings\")"
   ],
   "id": "eed314631871b511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Duplicates in Movies Metadata ---\n",
      "Duplicate groups based on keys ['id']: 29\n",
      "Fully duplicate rows (identical across all columns): 16\n",
      "\n",
      "Example duplicate rows based on keys:\n",
      "   adult                              belongs_to_collection    budget  \\\n",
      "0  False  {'id': 34055, 'name': 'Pokémon Collection', 'p...  16000000   \n",
      "1  False  {'id': 34055, 'name': 'Pokémon Collection', 'p...  16000000   \n",
      "2  False                                                NaN         0   \n",
      "3  False                                                NaN         0   \n",
      "4  False                                                NaN   3512454   \n",
      "5  False                                                NaN   3512454   \n",
      "6  False  {'id': 34055, 'name': 'Pokémon Collection', 'p...         0   \n",
      "7  False  {'id': 34055, 'name': 'Pokémon Collection', 'p...         0   \n",
      "8  False                                                NaN      2500   \n",
      "9  False                                                NaN      2500   \n",
      "\n",
      "                                              genres  \\\n",
      "0  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "2                      [{'id': 18, 'name': 'Drama'}]   \n",
      "3                      [{'id': 18, 'name': 'Drama'}]   \n",
      "4                      [{'id': 18, 'name': 'Drama'}]   \n",
      "5                      [{'id': 18, 'name': 'Drama'}]   \n",
      "6  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "7  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "8  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
      "9  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
      "\n",
      "                                            homepage      id    imdb_id  \\\n",
      "0                  http://movies.warnerbros.com/pk3/   10991  tt0235679   \n",
      "1                  http://movies.warnerbros.com/pk3/   10991  tt0235679   \n",
      "2                                                NaN  109962  tt0082992   \n",
      "3                                                NaN  109962  tt0082992   \n",
      "4                                                NaN  110428  tt2018086   \n",
      "5                                                NaN  110428  tt2018086   \n",
      "6  http://www.pokemon.com/us/movies/movie-pokemon...   12600  tt0287635   \n",
      "7  http://www.pokemon.com/us/movies/movie-pokemon...   12600  tt0287635   \n",
      "8                                                NaN   13209  tt0499537   \n",
      "9                                                NaN   13209  tt0499537   \n",
      "\n",
      "  original_language                  original_title  \\\n",
      "0                ja            Pokémon 3: The Movie   \n",
      "1                ja            Pokémon 3: The Movie   \n",
      "2                en                 Rich and Famous   \n",
      "3                en                 Rich and Famous   \n",
      "4                fr            Camille Claudel 1915   \n",
      "5                fr            Camille Claudel 1915   \n",
      "6                ja  劇場版ポケットモンスター セレビィ 時を越えた遭遇（であい）   \n",
      "7                ja  劇場版ポケットモンスター セレビィ 時を越えた遭遇（であい）   \n",
      "8                fa                         Offside   \n",
      "9                fa                         Offside   \n",
      "\n",
      "                                            overview  ...     revenue runtime  \\\n",
      "0  When Molly Hale's sadness of her father's disa...  ...  68411275.0    93.0   \n",
      "1  When Molly Hale's sadness of her father's disa...  ...  68411275.0    93.0   \n",
      "2  Two literary women compete for 20 years: one w...  ...         0.0   115.0   \n",
      "3  Two literary women compete for 20 years: one w...  ...         0.0   115.0   \n",
      "4  Winter, 1915. Confined by her family to an asy...  ...    115860.0    95.0   \n",
      "5  Winter, 1915. Confined by her family to an asy...  ...    115860.0    95.0   \n",
      "6  All your favorite Pokémon characters are back,...  ...  28023563.0    75.0   \n",
      "7  All your favorite Pokémon characters are back,...  ...  28023563.0    75.0   \n",
      "8  Since women are banned from soccer matches, Ir...  ...         0.0    93.0   \n",
      "9  Since women are banned from soccer matches, Ir...  ...         0.0    93.0   \n",
      "\n",
      "                            spoken_languages    status  \\\n",
      "0   [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "1   [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "2   [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "3   [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "4  [{'iso_639_1': 'fr', 'name': 'Français'}]  Released   \n",
      "5  [{'iso_639_1': 'fr', 'name': 'Français'}]  Released   \n",
      "6       [{'iso_639_1': 'ja', 'name': '日本語'}]  Released   \n",
      "7       [{'iso_639_1': 'ja', 'name': '日本語'}]  Released   \n",
      "8     [{'iso_639_1': 'fa', 'name': 'فارسی'}]  Released   \n",
      "9     [{'iso_639_1': 'fa', 'name': 'فارسی'}]  Released   \n",
      "\n",
      "                                             tagline  \\\n",
      "0                      Pokémon: Spell of the Unknown   \n",
      "1                      Pokémon: Spell of the Unknown   \n",
      "2  From the very beginning, they knew they'd be f...   \n",
      "3  From the very beginning, they knew they'd be f...   \n",
      "4                                                NaN   \n",
      "5                                                NaN   \n",
      "6                                                NaN   \n",
      "7                                                NaN   \n",
      "8                                                NaN   \n",
      "9                                                NaN   \n",
      "\n",
      "                                         title  video vote_average vote_count  \\\n",
      "0                Pokémon: Spell of the Unknown  False          6.0      144.0   \n",
      "1                Pokémon: Spell of the Unknown  False          6.0      143.0   \n",
      "2                              Rich and Famous  False          4.9        7.0   \n",
      "3                              Rich and Famous  False          4.9        7.0   \n",
      "4                         Camille Claudel 1915  False          7.0       20.0   \n",
      "5                         Camille Claudel 1915  False          7.0       20.0   \n",
      "6  Pokémon 4Ever: Celebi - Voice of the Forest  False          5.7       82.0   \n",
      "7  Pokémon 4Ever: Celebi - Voice of the Forest  False          5.7       82.0   \n",
      "8                                      Offside  False          6.7       27.0   \n",
      "9                                      Offside  False          6.7       27.0   \n",
      "\n",
      "             diff_columns  \n",
      "0  popularity, vote_count  \n",
      "1  popularity, vote_count  \n",
      "2              popularity  \n",
      "3              popularity  \n",
      "4              popularity  \n",
      "5              popularity  \n",
      "6              popularity  \n",
      "7              popularity  \n",
      "8              popularity  \n",
      "9              popularity  \n",
      "\n",
      "[10 rows x 25 columns]\n",
      "\n",
      "--- Checking Duplicates in Credits ---\n",
      "Duplicate groups based on keys ['id']: 43\n",
      "Fully duplicate rows (identical across all columns): 36\n",
      "\n",
      "Example duplicate rows based on keys:\n",
      "                                                cast  \\\n",
      "0  [{'cast_id': 15, 'character': 'Chuck Barris', ...   \n",
      "1  [{'cast_id': 15, 'character': 'Chuck Barris', ...   \n",
      "2  [{'cast_id': 1, 'character': 'Gerard Carriere'...   \n",
      "3  [{'cast_id': 1, 'character': 'Gerard Carriere'...   \n",
      "4  [{'cast_id': 1004, 'character': 'Luke Oarum', ...   \n",
      "5  [{'cast_id': 1004, 'character': 'Luke Oarum', ...   \n",
      "6  [{'cast_id': 3, 'character': 'Camille Claudel'...   \n",
      "7  [{'cast_id': 3, 'character': 'Camille Claudel'...   \n",
      "8  [{'cast_id': 4, 'character': 'Mihoko Nakagawa'...   \n",
      "9  [{'cast_id': 4, 'character': 'Mihoko Nakagawa'...   \n",
      "\n",
      "                                                crew      id diff_columns  \n",
      "0  [{'credit_id': '52fe43e2c3a36847f80760b5', 'de...    4912         crew  \n",
      "1  [{'credit_id': '52fe43e2c3a36847f80760a9', 'de...    4912         crew  \n",
      "2  [{'credit_id': '5468acec22136e68c9000d53', 'de...   69234         crew  \n",
      "3  [{'credit_id': '52fe47bfc3a368484e0d77bf', 'de...   69234         crew  \n",
      "4  [{'credit_id': '52fe4a269251416c750df623', 'de...   99080         crew  \n",
      "5  [{'credit_id': '52fe4a269251416c750df61d', 'de...   99080         crew  \n",
      "6  [{'credit_id': '52fe4ad6c3a36847f81e461b', 'de...  110428         crew  \n",
      "7  [{'credit_id': '577ed5389251416976004432', 'de...  110428         crew  \n",
      "8  [{'credit_id': '56365ed9925141285701b06e', 'de...  132641         crew  \n",
      "9  [{'credit_id': '52fe4b9ac3a368484e190d25', 'de...  132641         crew  \n",
      "\n",
      "--- Checking Duplicates in Keywords ---\n",
      "Duplicate groups based on keys ['id']: 985\n",
      "Fully duplicate rows (identical across all columns): 985\n",
      "\n",
      "--- Checking Duplicates in Links ---\n",
      "Duplicate groups based on keys ['movieId']: 0\n",
      "Fully duplicate rows (identical across all columns): 0\n",
      "\n",
      "--- Checking Duplicates in Ratings ---\n",
      "Duplicate groups based on keys ['movieId', 'userId']: 0\n",
      "Fully duplicate rows (identical across all columns): 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userId, movieId, rating, timestamp]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:29:36.861470Z",
     "start_time": "2025-10-31T11:29:36.508871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Movies ---\n",
    "if \"id\" in movies.columns:\n",
    "    movies[\"id\"] = pd.to_numeric(movies[\"id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    invalid = movies[\"id\"].isna().sum()\n",
    "    print(f\"movies: converted 'id' to numeric ({invalid} invalid IDs)\")\n",
    "\n",
    "# --- Credits ---\n",
    "if \"id\" in movie_credits.columns and \"movie_id\" not in movie_credits.columns:\n",
    "    movie_credits.rename(columns={\"id\": \"movie_id\"}, inplace=True)\n",
    "movie_credits[\"movie_id\"] = pd.to_numeric(movie_credits[\"movie_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "invalid = movie_credits[\"movie_id\"].isna().sum()\n",
    "print(f\"credits: normalized 'movie_id' ({invalid} invalid IDs)\")\n",
    "\n",
    "# --- Keywords ---\n",
    "if \"id\" in keywords.columns and \"movie_id\" not in keywords.columns:\n",
    "    keywords.rename(columns={\"id\": \"movie_id\"}, inplace=True)\n",
    "keywords[\"movie_id\"] = pd.to_numeric(keywords[\"movie_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "invalid = keywords[\"movie_id\"].isna().sum()\n",
    "print(f\"keywords: normalized 'movie_id' ({invalid} invalid IDs)\")\n",
    "\n",
    "# --- Links ---\n",
    "# Normalize TMDb ID\n",
    "if \"tmdbId\" in links.columns:\n",
    "    links.rename(columns={\"tmdbId\": \"tmdb_id\"}, inplace=True)\n",
    "    links[\"tmdb_id\"] = pd.to_numeric(links[\"tmdb_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    invalid = links[\"tmdb_id\"].isna().sum()\n",
    "    print(f\"links: normalized 'tmdb_id' ({invalid} invalid IDs)\")\n",
    "\n",
    "# Normalize MovieLens ID\n",
    "if \"movieId\" in links.columns:\n",
    "    links.rename(columns={\"movieId\": \"movie_lens_id\"}, inplace=True)\n",
    "links[\"movie_lens_id\"] = pd.to_numeric(links[\"movie_lens_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Normalize IMDb ID (optional, if you want)\n",
    "if \"imdbId\" in links.columns:\n",
    "    links.rename(columns={\"imdbId\": \"imdb_id\"}, inplace=True)\n",
    "    links[\"imdb_id\"] = pd.to_numeric(links[\"imdb_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "\n",
    "# --- Ratings ---\n",
    "if \"movieId\" in ratings.columns:\n",
    "    ratings.rename(columns={\"movieId\": \"movie_lens_id\"}, inplace=True)\n",
    "ratings[\"movie_lens_id\"] = pd.to_numeric(ratings[\"movie_lens_id\"], errors=\"coerce\").astype(\"Int64\")"
   ],
   "id": "367326edddc28283",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies: converted 'id' to numeric (3 invalid IDs)\n",
      "credits: normalized 'movie_id' (0 invalid IDs)\n",
      "keywords: normalized 'movie_id' (0 invalid IDs)\n",
      "links: normalized 'tmdb_id' (219 invalid IDs)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:29:41.972189Z",
     "start_time": "2025-10-31T11:29:41.663008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_invalid_references(df, id_col, name, valid_ids):\n",
    "    if id_col not in df.columns:\n",
    "        print(f\"{name}: no '{id_col}' column, skipped validation\")\n",
    "        return\n",
    "    total = len(df)\n",
    "    invalid = (~df[id_col].isin(valid_ids)).sum()\n",
    "    print(f\"{name}: {invalid} invalid '{id_col}' references out of {total} rows\")\n",
    "\n",
    "\n",
    "# --- Prepare sets of valid IDs ---\n",
    "valid_tmdb_ids = set(movies[\"id\"].dropna())\n",
    "valid_link_ids = set(links[\"movie_lens_id\"].dropna())\n",
    "\n",
    "# --- Validate ---\n",
    "# Credits → Movies\n",
    "count_invalid_references(movie_credits, \"movie_id\", \"credits\", valid_tmdb_ids)\n",
    "\n",
    "# Keywords → Movies\n",
    "count_invalid_references(keywords, \"movie_id\", \"keywords\", valid_tmdb_ids)\n",
    "\n",
    "# Links → Movies\n",
    "count_invalid_references(links, \"tmdb_id\", \"links\", valid_tmdb_ids)\n",
    "\n",
    "# Ratings → Links\n",
    "count_invalid_references(ratings, \"movie_lens_id\", \"ratings\", valid_link_ids)\n"
   ],
   "id": "5ea7a47a9f7253ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credits: 0 invalid 'movie_id' references out of 45476 rows\n",
      "keywords: 0 invalid 'movie_id' references out of 46419 rows\n",
      "links: 380 invalid 'tmdb_id' references out of 45843 rows\n",
      "ratings: 0 invalid 'movie_lens_id' references out of 26024289 rows\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1e929c11d75eca01"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
